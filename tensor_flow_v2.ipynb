{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b815d9-1e77-4681-af9b-01368da7b7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 17:28:12.448500: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-28 17:28:12.450825: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-28 17:28:12.486433: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-28 17:28:12.487958: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 17:28:13.195184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5cb87944-6e0b-402e-9761-8fd179278cd7",
   "metadata": {},
   "source": [
    "# Directories of image folders\n",
    "fake_folder = \"fake_images/fake\"\n",
    "real_folder = \"img_align_celeba/real\"\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "epochs = 30  # Increased number of epochs by 3x\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "# Lists of image files\n",
    "fake_files = [os.path.join(fake_folder, file) for file in os.listdir(fake_folder)]\n",
    "real_files = [os.path.join(real_folder, file) for file in os.listdir(real_folder)]\n",
    "\n",
    "# Randomly select 3000 fake and 3000 real images\n",
    "random.seed(42)  # Set a random seed for reproducibility\n",
    "selected_fake_files = random.sample(fake_files, 3000)\n",
    "selected_real_files = random.sample(real_files, 3000)\n",
    "\n",
    "# Combine the lists of selected files and labels (0 for fake and 1 for real)\n",
    "selected_files = selected_fake_files + selected_real_files\n",
    "selected_labels = [0] * 3000 + [1] * 3000\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "selected_labels = np.array(selected_labels)\n",
    "\n",
    "# Create a pandas DataFrame with 'File' and 'Label' columns\n",
    "df = pd.DataFrame({'File': selected_files, 'Label': selected_labels})\n",
    "\n",
    "# Data preprocessing with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20, # Now rotate images randomly up to 20 degrees\n",
    "    zoom_range=0.2, # Zoom in on images randomly up to 20%\n",
    "    horizontal_flip=True, # Flip images horizontally\n",
    "    validation_split=0.1\n",
    "    )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    x_col='File',\n",
    "    y_col='Label',\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='raw',  # Changed to 'raw' to work with numerical labels\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    x_col='File',\n",
    "    y_col='Label',\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='raw',  # Changed to 'raw' to work with numerical labels\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# CNN architecture definition, with more  convolultional layers and dropout\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5), # Add dropout layer\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5), # Add dropout layer\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75579cb5-06ed-403e-9264-1bc86bd3b776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb153652-86a7-4b7b-814f-83c687cd03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation, add custom lr \n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Adjust learning rate\n",
    "        loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486a359f-4ae6-40f7-8f52-5250ac36fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22/22 [==============================] - 220s 10s/step - loss: 0.6752 - accuracy: 0.5581 - val_loss: 0.7632 - val_accuracy: 0.0500\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 199s 9s/step - loss: 0.5743 - accuracy: 0.7194 - val_loss: 0.5691 - val_accuracy: 0.7517\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 197s 9s/step - loss: 0.4160 - accuracy: 0.8198 - val_loss: 0.2719 - val_accuracy: 0.9100\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 205s 9s/step - loss: 0.2987 - accuracy: 0.8826 - val_loss: 0.2595 - val_accuracy: 0.9050\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 205s 9s/step - loss: 0.2161 - accuracy: 0.9167 - val_loss: 0.3795 - val_accuracy: 0.8383\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 208s 9s/step - loss: 0.1818 - accuracy: 0.9344 - val_loss: 0.1356 - val_accuracy: 0.9483\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 200s 9s/step - loss: 0.1377 - accuracy: 0.9506 - val_loss: 0.1430 - val_accuracy: 0.9467\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 210s 10s/step - loss: 0.1144 - accuracy: 0.9600 - val_loss: 0.1234 - val_accuracy: 0.9517\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 212s 10s/step - loss: 0.0994 - accuracy: 0.9650 - val_loss: 0.0713 - val_accuracy: 0.9833\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 211s 10s/step - loss: 0.0836 - accuracy: 0.9722 - val_loss: 0.1042 - val_accuracy: 0.9600\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 204s 9s/step - loss: 0.0711 - accuracy: 0.9776 - val_loss: 0.0873 - val_accuracy: 0.9700\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 203s 9s/step - loss: 0.0648 - accuracy: 0.9796 - val_loss: 0.0348 - val_accuracy: 0.9867\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 206s 9s/step - loss: 0.0580 - accuracy: 0.9804 - val_loss: 0.0306 - val_accuracy: 0.9900\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 208s 9s/step - loss: 0.0495 - accuracy: 0.9841 - val_loss: 0.0457 - val_accuracy: 0.9833\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 205s 9s/step - loss: 0.0464 - accuracy: 0.9850 - val_loss: 0.0300 - val_accuracy: 0.9933\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 206s 9s/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 0.0367 - val_accuracy: 0.9867\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 200s 9s/step - loss: 0.0472 - accuracy: 0.9848 - val_loss: 0.0443 - val_accuracy: 0.9883\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 201s 9s/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 0.0252 - val_accuracy: 0.9883\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 200s 9s/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 200s 9s/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0150 - val_accuracy: 0.9950\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 198s 9s/step - loss: 0.0400 - accuracy: 0.9893 - val_loss: 0.0064 - val_accuracy: 0.9983\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 199s 9s/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.0373 - val_accuracy: 0.9850\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 197s 9s/step - loss: 0.0269 - accuracy: 0.9922 - val_loss: 0.0188 - val_accuracy: 0.9950\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 199s 9s/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.0174 - val_accuracy: 0.9950\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 201s 9s/step - loss: 0.0267 - accuracy: 0.9919 - val_loss: 0.0585 - val_accuracy: 0.9783\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 198s 9s/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0389 - val_accuracy: 0.9833\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 214s 10s/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0299 - val_accuracy: 0.9900\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 198s 9s/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0293 - val_accuracy: 0.9883\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 200s 9s/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0111 - val_accuracy: 0.9967\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 201s 9s/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0156 - val_accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff1c60d3390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "model.fit(train_generator, epochs=epochs, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e094c32-eb47-49ab-abf6-22dcf8566e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 25s 7s/step - loss: 0.0284 - accuracy: 0.9883\n",
      "Accuracy on the validation set: 98.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Accuracy on the validation set: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Saving the trained model\n",
    "model.save('classification_real_fake_model_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6bbbc-16f5-40d1-a03c-da1f513ffbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
